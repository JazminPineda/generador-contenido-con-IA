# Generador de Contenido para Blogs usando Ollama
## Descripción General

Este proyecto implementa una herramienta de generación automática de publicaciones para un blog personal, a partir de un tema proporcionado por el usuario. Mediante un prompt adaptado, el modelo devuelve textos con el tono y formato solicitado.

La solución fue desarrollada en Python, utilizando LangChain y el framework Ollama, que permite la ejecución local de modelos de lenguaje de gran escala (LLM). Con ello, se busca demostrar conocimientos en integración de IA, despliegue de modelos open-source y adaptación de herramientas a recursos limitados (CPU/RAM).

Este proyecto forma parte de mi portafolio personal, con el objetivo de evidenciar aprendizajes técnicos, experiencia práctica e interacción con modelos de IA en entornos reales de desarrollo.

## Tecnologías y Herramientas

**Lenguaje:** Python.

**Entorno:** Visual Studio Code.

**Frameworks/Modelos:** LangChain + Ollama  y LLM open-source.

## Aprendizajes Clave 

- LLM con LangChain: Integración de modelo llama3:8b.

- Ollama: Herramienta open-source que facilita la ejecución local de LLM, gestionando pesos y ejecutado de manera local.

- Optimización de recursos: Selección de modelos adecuados según la memoria RAM disponible y configuración de prompts personalizados para distintos casos de uso.

## Objetivos del Proyecto

* Conocer las libreias y como hacer integraciones con IA. 

* Implementar comunicación local con modelos a través de prompts prediseñados.

* Explorar configuraciones flexibles de LLM y evaluar su rendimiento en un entorno de escritorio.

## Referencias

[LangChain Ollama](https://python.langchain.com/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html)